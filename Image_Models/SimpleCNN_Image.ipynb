{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing necessary modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "import PIL\n",
    "from PIL import Image,UnidentifiedImageError\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,Activation\n",
    "from keras.models import save_model,load_model\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting up the image size and max image pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "IMG_SIZE = (120,120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setting up the Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET PATHS\n",
    "DATASET_DIR = Path('NEW_DATASET_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Up Directories\n",
    "\n",
    "# TRAIN DATA PATH\n",
    "TRAIN_CSV_PATH = os.path.join(DATASET_DIR,'TRAIN','multimodal_train.csv')\n",
    "TRAIN_IMG_PATH = os.path.join(DATASET_DIR,'TRAIN','IMAGES')\n",
    "\n",
    "# TEST DATA PATH\n",
    "TEST_CSV_PATH = os.path.join(DATASET_DIR,'TEST','multimodal_test.csv')\n",
    "TEST_IMG_PATH = os.path.join(DATASET_DIR,'TEST','IMAGES')\n",
    "\n",
    "# VALIDATE DATA PATH\n",
    "VALIDATE_CSV_PATH = os.path.join(DATASET_DIR,'VALIDATE','multimodal_validate.csv')\n",
    "VALIDATE_IMG_PATH = os.path.join(DATASET_DIR,'VALIDATE','IMAGES')\n",
    "\n",
    "# PRE_PROCESSED DATA PATHS\n",
    "PRE_PROCESSED_TRAIN_DATA_PATH = os.path.join(DATASET_DIR,'PROCESSED_DATA','train_data.npz')\n",
    "PRE_PROCESSED_TEST_DATA_PATH = os.path.join(DATASET_DIR,'PROCESSED_DATA','test_data.npz')\n",
    "PRE_PROCESSED_VALIDATE_DATA_PATH = os.path.join(DATASET_DIR,'PROCESSED_DATA','validate_data.npz')\n",
    "\n",
    "# Model Outputs\n",
    "MODEL_OUTPUT_DIR = Path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading the Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1       author  \\\n",
       "0      436310        436310   jessicaO_o   \n",
       "1      112761        112761          NaN   \n",
       "2      335972        335972     Duckitor   \n",
       "3      185095        185095    SuperKozz   \n",
       "4      189772        189772  nicksatdown   \n",
       "\n",
       "                                         clean_title   created_utc  \\\n",
       "0  this perfectlysized woody doll stuck to the ba...  1.569282e+09   \n",
       "1                      large man jumping into a pool  1.406789e+09   \n",
       "2  cops man sets up fake dui checkpoint gets char...  1.460131e+09   \n",
       "3                            turtle enjoying the sun  1.512896e+09   \n",
       "4  grandfather who beat three types of cancer com...  1.421564e+09   \n",
       "\n",
       "            domain  hasImage      id  \\\n",
       "0        i.redd.it      True  d8evxg   \n",
       "1     dumpaday.com      True  2c7vxd   \n",
       "2         wtae.com      True  4dwzqp   \n",
       "3        i.redd.it      True  7iszja   \n",
       "4  telegraph.co.uk      True  2st8j2   \n",
       "\n",
       "                                           image_url linked_submission_id  \\\n",
       "0  https://preview.redd.it/mss81mprifo31.jpg?widt...                  NaN   \n",
       "1  https://external-preview.redd.it/g7DkrdPEupDdZ...                  NaN   \n",
       "2  https://external-preview.redd.it/twPZ8mH_gGc--...                  NaN   \n",
       "3  https://preview.redd.it/2na6m5s382301.jpg?widt...                  NaN   \n",
       "4  https://external-preview.redd.it/FBf2kiPgNr8K5...                  NaN   \n",
       "\n",
       "   num_comments  score          subreddit  \\\n",
       "0           4.0     37  mildlyinteresting   \n",
       "1          24.0     64   photoshopbattles   \n",
       "2           0.0     36        nottheonion   \n",
       "3           5.0     11   photoshopbattles   \n",
       "4           1.0     23      upliftingnews   \n",
       "\n",
       "                                               title  upvote_ratio  \\\n",
       "0  This perfectly-sized Woody doll stuck to the b...          0.78   \n",
       "1                      Large man jumping into a pool          0.72   \n",
       "2  Cops: Man sets up fake DUI checkpoint, gets ch...          0.81   \n",
       "3                  PsBattle: Turtle enjoying the sun          0.84   \n",
       "4  Grandfather who beat three types of cancer com...          0.85   \n",
       "\n",
       "   2_way_label  3_way_label  6_way_label  \n",
       "0            1            0            0  \n",
       "1            1            0            0  \n",
       "2            1            0            0  \n",
       "3            1            0            0  \n",
       "4            1            0            0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>author</th>\n      <th>clean_title</th>\n      <th>created_utc</th>\n      <th>domain</th>\n      <th>hasImage</th>\n      <th>id</th>\n      <th>image_url</th>\n      <th>linked_submission_id</th>\n      <th>num_comments</th>\n      <th>score</th>\n      <th>subreddit</th>\n      <th>title</th>\n      <th>upvote_ratio</th>\n      <th>2_way_label</th>\n      <th>3_way_label</th>\n      <th>6_way_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>436310</td>\n      <td>436310</td>\n      <td>jessicaO_o</td>\n      <td>this perfectlysized woody doll stuck to the ba...</td>\n      <td>1.569282e+09</td>\n      <td>i.redd.it</td>\n      <td>True</td>\n      <td>d8evxg</td>\n      <td>https://preview.redd.it/mss81mprifo31.jpg?widt...</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>37</td>\n      <td>mildlyinteresting</td>\n      <td>This perfectly-sized Woody doll stuck to the b...</td>\n      <td>0.78</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>112761</td>\n      <td>112761</td>\n      <td>NaN</td>\n      <td>large man jumping into a pool</td>\n      <td>1.406789e+09</td>\n      <td>dumpaday.com</td>\n      <td>True</td>\n      <td>2c7vxd</td>\n      <td>https://external-preview.redd.it/g7DkrdPEupDdZ...</td>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>64</td>\n      <td>photoshopbattles</td>\n      <td>Large man jumping into a pool</td>\n      <td>0.72</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>335972</td>\n      <td>335972</td>\n      <td>Duckitor</td>\n      <td>cops man sets up fake dui checkpoint gets char...</td>\n      <td>1.460131e+09</td>\n      <td>wtae.com</td>\n      <td>True</td>\n      <td>4dwzqp</td>\n      <td>https://external-preview.redd.it/twPZ8mH_gGc--...</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>36</td>\n      <td>nottheonion</td>\n      <td>Cops: Man sets up fake DUI checkpoint, gets ch...</td>\n      <td>0.81</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>185095</td>\n      <td>185095</td>\n      <td>SuperKozz</td>\n      <td>turtle enjoying the sun</td>\n      <td>1.512896e+09</td>\n      <td>i.redd.it</td>\n      <td>True</td>\n      <td>7iszja</td>\n      <td>https://preview.redd.it/2na6m5s382301.jpg?widt...</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>11</td>\n      <td>photoshopbattles</td>\n      <td>PsBattle: Turtle enjoying the sun</td>\n      <td>0.84</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>189772</td>\n      <td>189772</td>\n      <td>nicksatdown</td>\n      <td>grandfather who beat three types of cancer com...</td>\n      <td>1.421564e+09</td>\n      <td>telegraph.co.uk</td>\n      <td>True</td>\n      <td>2st8j2</td>\n      <td>https://external-preview.redd.it/FBf2kiPgNr8K5...</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>23</td>\n      <td>upliftingnews</td>\n      <td>Grandfather who beat three types of cancer com...</td>\n      <td>0.85</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_csv_df = pd.read_csv(TRAIN_CSV_PATH,low_memory=False)\n",
    "train_csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check for skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = train_csv_df.groupby(['2_way_label'])\n",
    "true_df = grouped_df.get_group(1)\n",
    "false_df = grouped_df.get_group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(28200, 18)\n(28200, 18)\n"
     ]
    }
   ],
   "source": [
    "print(true_df.shape)\n",
    "print(false_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extracting only necessary fields from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(56400, 2)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            id  2_way_label\n",
       "44771   90f69w            0\n",
       "3754    86spl5            1\n",
       "4960    13nri7            1\n",
       "50598  dc8zn4a            0\n",
       "41337  cjjosiu            0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>2_way_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44771</th>\n      <td>90f69w</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3754</th>\n      <td>86spl5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4960</th>\n      <td>13nri7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>50598</th>\n      <td>dc8zn4a</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41337</th>\n      <td>cjjosiu</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "train_df = shuffle(train_csv_df[['id','2_way_label']])\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to check wether the loaded image is corrupted or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isImgCorrupted(img):\n",
    "    try:\n",
    "        im = Image.open(img)\n",
    "        im.verify()\n",
    "        return False\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return True\n",
    "    \n",
    "    except SyntaxError:\n",
    "        return True\n",
    "    \n",
    "    except PIL.UnidentifiedImageError:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index: 44771\nIMG = 90f69w, Label = 0\nIndex: 3754\nIMG = 86spl5, Label = 1\nIndex: 4960\nIMG = 13nri7, Label = 1\nIndex: 50598\nIMG = dc8zn4a, Label = 0\nIndex: 41337\nIMG = cjjosiu, Label = 0\n"
     ]
    }
   ],
   "source": [
    "# TESTING PURPOSES\n",
    "for i, row in train_df.head().iterrows():\n",
    "    print('Index: {}'.format(i))\n",
    "    img, label = row.tolist()\n",
    "    print(f'IMG = {img}, Label = {label}')\n",
    "\n",
    "# img,label = train_csv_df.loc[0,['id','2_way_label']].tolist()\n",
    "# # train_df.shape\n",
    "# img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to preprocess the dataframe to required fields\n",
    "    - Checks for Image Corruption\n",
    "    - Converts the Image data to numpy array\n",
    "    - Returns\n",
    "        - X -> contains all the image data \n",
    "        - Y -> contains the labels of images\n",
    "        - id -> id's of the respective images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImageData(df,IMG_PATH):\n",
    "    X = []\n",
    "    y = []\n",
    "    id = []\n",
    " \n",
    "    with alive_bar(df.shape[0],title='Processing Image Data') as pbar:\n",
    "        for i, row in df.iterrows():\n",
    "            img, label = row.tolist()\n",
    "            impath = os.path.join(IMG_PATH, f'{img}.jpg')\n",
    "            try:\n",
    "                if not isImgCorrupted(impath):\n",
    "                    imarray = cv.imread(impath, cv.IMREAD_GRAYSCALE)\n",
    "                    if imarray is not None:\n",
    "                        new_imarray = cv.resize(imarray, IMG_SIZE)\n",
    "                        X.append(new_imarray)\n",
    "                        y.append(label)\n",
    "                        id.append(img)\n",
    "    \n",
    "            except Exception as e:\n",
    "                print(f\"{img}: {e}\")\n",
    "            pbar()\n",
    "    # for i, row in df.iterrows():\n",
    "    #     img, label = row.tolist()\n",
    "    #     impath = os.path.join(IMG_PATH, f'{img}.jpg')\n",
    "    #     try:\n",
    "    #         if not isImgCorrupted(impath):\n",
    "    #             imarray = cv.imread(impath, cv.IMREAD_GRAYSCALE)\n",
    "    #             if imarray is not None:\n",
    "    #                 new_imarray = cv.resize(imarray, IMG_SIZE)\n",
    "    #                 X.append(new_imarray)\n",
    "    #                 y.append(label)\n",
    "    #                 id.append(img)\n",
    " \n",
    "    #     except Exception as e:\n",
    "    #         print(f\"{img}: {e}\")\n",
    " \n",
    "    # Converting X, y,id to numpy array\n",
    "    X = np.array(X).reshape(-1,120,120,1)\n",
    "    y = np.array(y)\n",
    "    id = np.array(id)\n",
    " \n",
    "    # Normalize X\n",
    "    X = X / 255.0\n",
    " \n",
    "    return (X,y,id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocessing the Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(56357, 120, 120, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "X_train, y_train, _ = preprocessImageData(train_df,TRAIN_IMG_PATH)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the training data\n",
    "# np.save(r'Image_Processing\\X_train.npy',X_train)\n",
    "# np.save(r'Image_Processing\\y_train.npy',y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training data. Use only in need\n",
    "\n",
    "# data = np.load(PRE_PROCESSED_TRAIN_DATA_PATH)\n",
    "# X_train = data['x']\n",
    "# y_train = data['y']\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining & Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the model with l2 regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "model = Sequential()\n",
    "# Adding a densely-connected layer with 64 units to the model\n",
    "model.add(Conv2D(64, (3,3), activation='relu',input_shape=(120,120,1),kernel_regularizer='l2'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# Add another\n",
    "model.add(Conv2D(64, (3,3), activation='relu',kernel_regularizer='l2'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model,show_layer_names=True,show_shapes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# # Adding a densely-connected layer with 64 units to the model\n",
    "# model.add(Conv2D(64, (3,3), activation='relu',input_shape=input_shape,kernel_regularizer='l2'))\n",
    "# model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# # Add another\n",
    "# model.add(Conv2D(64, (3,3), activation='relu',kernel_regularizer='l2'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# # Add another\n",
    "# model.add(Conv2D(64, (3,3), activation='relu',kernel_regularizer='l2'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# # Add another\n",
    "# model.add(Conv2D(64, (3,3), activation='relu',kernel_regularizer='l2'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# for i in range(4):\n",
    "#     model.add(Dense(64,activation='relu'))\n",
    "\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#                     loss='binary_crossentropy',\n",
    "#                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d7a18a7ad35e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1038\u001b[0m       \u001b[1;31m# `Tensor` and `NumPy` input.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       (x, y, sample_weight), validation_data = (\n\u001b[1;32m-> 1040\u001b[1;33m           data_adapter.train_validation_split(\n\u001b[0m\u001b[0;32m   1041\u001b[0m               (x, y, sample_weight), validation_split=validation_split))\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msplit_at\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msplit_at\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m   1376\u001b[0m         \u001b[1;34m\"Training data contains {batch_dim} samples, which is not sufficient \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m         \u001b[1;34m\"to split it into a validation and training set as specified by \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument."
     ]
    }
   ],
   "source": [
    "model_history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Displaying the accuracy & loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# plt.savefig('Image_Processing_Outputs\\model_accuracy.pdf')\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('Image_Processing_Outputs\\model_loss.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'Image_Processing\\model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load back model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(r'Image_Processing\\model.h5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predicting Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_csv_df = pd.read_csv(TEST_CSV_PATH)\n",
    "test_csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_csv_df[['id','2_way_label']]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, id = preprocessImageData(test_df, TEST_IMG_FOLDER_PATH)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the Text data\n",
    "# np.save(r'Image_Processing\\X_test.npy',X_test)\n",
    "# np.save(r'Image_Processing\\y_test.npy',y_test)\n",
    "# np.save(r'Image_Processing\\id.npy',id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Text Data\n",
    "\n",
    "# data = np.load(PRE_PROCESSED_TEST_DATA_PATH)\n",
    "# X_test,y_test,id = data['x'],data['y'],data['id']\n",
    "# print(X_test.shape[1:])\n",
    "# print(y_test.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding the results\n",
    "predicted_val = [int(round(p[0])) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    'Image ID' : id,\n",
    "    'Correct O/P' : y_test,\n",
    "    'Predicted O/P' : predicted_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results_dict)\n",
    "result_df.to_csv('Image_Processing_Simple_CNN_Results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0d4180bf7152e7c6f8a3ea8742aba052dd041fa5880fbd19b9b10502a787e45a0",
   "display_name": "Python 3.8.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}